{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Perceptron.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN+poFTCSz4llo1o9PI47dW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChiaYunn/TensorFlow/blob/main/Perceptron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d72iBE3nrnOR",
        "outputId": "d10f1650-0386-46ff-f4c8-12fb0403830d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "class Perceptron:\n",
        "  def __init__(self, input_length, weights=None, bias=None):\n",
        "    if weights is None:\n",
        "      self.weights = np.ones(input_length) * 1\n",
        "    else:\n",
        "      self.weights = weights\n",
        "    if bias is None:\n",
        "      self.bias = -1\n",
        "    else:\n",
        "      self.bias = bias\n",
        "\n",
        "  @staticmethod\n",
        "  def activation_function(x):\n",
        "    if x > 0:\n",
        "      return 1\n",
        "    return 0\n",
        "\n",
        "  def __call__(self, input_data):\n",
        "    weighted_input = self.weights * input_data\n",
        "    weighted_sum = weighted_input.sum() + self.bias\n",
        "    return Perceptron.activation_function(weighted_sum)\n",
        "\n",
        "weights = np.array([1, 1])\n",
        "bias = -1\n",
        "AND_Gate = Perceptron(2, weights, bias)\n",
        "\n",
        "input_data = [np.array([0, 0]), np.array([0, 1]), np.array([1, 0]), np.array([1, 1])]\n",
        "for x in input_data:\n",
        "  out = AND_Gate(np.array(x))\n",
        "  print(x, out)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0] 0\n",
            "[0 1] 0\n",
            "[1 0] 0\n",
            "[1 1] 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLvP-9aJwqxi",
        "outputId": "2df35411-ad30-4644-b023-b7e79a49234c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "class Perceptron:\n",
        "  def __init__(self, input_length, weights=None, bias=None):\n",
        "    if weights is None:\n",
        "      self.weights = np.ones(input_length) * 1\n",
        "    else:\n",
        "      self.weights = weights\n",
        "    if bias is None:\n",
        "      self.bias = -1\n",
        "    else:\n",
        "      self.bias = bias\n",
        "\n",
        "  @staticmethod\n",
        "  def activation_function(x):\n",
        "    if x > 0:\n",
        "      return 1\n",
        "    return 0\n",
        "\n",
        "  def __call__(self, input_data):\n",
        "    weighted_input = self.weights * input_data\n",
        "    weighted_sum = weighted_input.sum() + self.bias\n",
        "    return Perceptron.activation_function(weighted_sum)\n",
        "\n",
        "weights = np.array([1, 1])\n",
        "bias = -0.5\n",
        "OR_Gate = Perceptron(2, weights, bias)\n",
        "\n",
        "input_data = [np.array([0, 0]), np.array([0, 1]), np.array([1, 0]), np.array([1, 1])]\n",
        "for x in input_data:\n",
        "  out = OR_Gate(np.array(x))\n",
        "  print(x, out)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0] 0\n",
            "[0 1] 1\n",
            "[1 0] 1\n",
            "[1 1] 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XDEOLGJ1Pn7",
        "outputId": "e180dbc1-46a9-4c3d-acf7-f41bdc9d69b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "class Perceptron:\n",
        "  def __init__(self, input_length, weights=None, bias=None):\n",
        "    if weights is None:\n",
        "      self.weights = np.ones(input_length) * 1\n",
        "    else:\n",
        "      self.weights = weights\n",
        "    if bias is None:\n",
        "      self.bias = -1\n",
        "    else:\n",
        "      self.bias = bias\n",
        "\n",
        "  @staticmethod\n",
        "  def activation_function(x):\n",
        "    if x > 0:\n",
        "      return 1\n",
        "    return 0\n",
        "\n",
        "  def __call__(self, input_data):\n",
        "    weighted_input = self.weights * input_data\n",
        "    weighted_sum = weighted_input.sum() + self.bias\n",
        "    return Perceptron.activation_function(weighted_sum)\n",
        "\n",
        "weights = np.array([-1, -1])\n",
        "bias = 1.5\n",
        "Nand_Gate = Perceptron(2, weights, bias)\n",
        "\n",
        "input_data = [np.array([0, 0]), np.array([0, 1]), np.array([1, 0]), np.array([1, 1])]\n",
        "for x in input_data:\n",
        "  out = Nand_Gate(np.array(x))\n",
        "  print(x, out)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0] 1\n",
            "[0 1] 1\n",
            "[1 0] 1\n",
            "[1 1] 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7c0O6oD_223A",
        "outputId": "360da222-631e-43de-ef54-1a7afb281bfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "class Perceptron:\n",
        "  def __init__(self, input_length, weights=None, bias=None):\n",
        "    if weights is None:\n",
        "      self.weights = np.ones(input_length) * 1\n",
        "    else:\n",
        "      self.weights = weights\n",
        "    if bias is None:\n",
        "      self.bias = -1\n",
        "    else:\n",
        "      self.bias = bias\n",
        "\n",
        "  @staticmethod\n",
        "  def activation_function(x):\n",
        "    if x > 0:\n",
        "      return 1\n",
        "    return 0\n",
        "\n",
        "  def __call__(self, input_data):\n",
        "    weighted_input = self.weights * input_data\n",
        "    weighted_sum = weighted_input.sum() + self.bias\n",
        "    return Perceptron.activation_function(weighted_sum)\n",
        "\n",
        "weights = np.array([-1, -1])\n",
        "bias = 1\n",
        "Nand_Gate = Perceptron(2, weights, bias)\n",
        "\n",
        "input_data = [np.array([0, 0]), np.array([0, 1]), np.array([1, 0]), np.array([1, 1])]\n",
        "for x in input_data:\n",
        "  out = Nand_Gate(np.array(x))\n",
        "  print(x, out)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0] 1\n",
            "[0 1] 0\n",
            "[1 0] 0\n",
            "[1 1] 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bV2Gt6hK8LGB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}